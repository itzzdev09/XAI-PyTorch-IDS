# main_catboost.py
import os
import time
import json
from datetime import datetime
import warnings

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.utils import resample

from catboost import CatBoostClassifier, Pool, CatBoostError
import shap

# --------------------
# Config
# --------------------
DATA_PATH = "data/processed/simargl_full.parquet"  # combined dataset
RUNS_DIR = "Runs"
os.makedirs(RUNS_DIR, exist_ok=True)

PER_CLASS_MAX = 250_000
N_SPLITS = 5  # k for k-fold
RANDOM_STATE = 42

CB_PARAMS_GPU = {
    "loss_function": "MultiClass",
    "eval_metric": "MultiClass",
    "iterations": 800,
    "depth": 6,
    "learning_rate": 0.1,
    "l2_leaf_reg": 3.0,
    "random_seed": RANDOM_STATE,
    "task_type": "GPU",
    "devices": "0",
    "auto_class_weights": "SqrtBalanced",
    "rsm": 0.8,
    "bootstrap_type": "Bernoulli",
    "subsample": 0.8,
    "gpu_ram_part": 0.85,
    "verbose": 100,
    "use_best_model": False
}

CB_PARAMS_CPU = {**{k: v for k, v in CB_PARAMS_GPU.items() if k not in ["task_type", "devices", "gpu_ram_part"]},
                 "task_type": "CPU", "thread_count": os.cpu_count()}

CHUNK_ITERS = 200

# --------------------
# Helpers
# --------------------
def start_run_dir():
    d = os.path.join(RUNS_DIR, f"Run_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}")
    os.makedirs(d, exist_ok=True)
    return d

def load_dataset(path):
    if not os.path.exists(path):
        raise FileNotFoundError(f"‚ùå Dataset not found at {path}")
    print(f"üìÇ Loading dataset: {path}")
    df = pd.read_parquet(path)
    print(f"‚úÖ Dataset shape: {df.shape}")
    if "Label" not in df.columns:
        raise ValueError("‚ùå 'Label' column missing in dataset.")
    print("‚úÖ Class distribution:\n", df["Label"].value_counts())
    return df

def infer_and_fix_types(df):
    """Infer and fix dtypes for CatBoost, without blowing up memory."""

    cat_cols = []
    num_cols = []

    for c in df.columns:
        if c.lower() in ["label", "target"]:  # skip label
            continue

        # If column is numeric-like already ‚Üí force to float32 (smaller memory than int64)
        if pd.api.types.is_numeric_dtype(df[c]):
            df[c] = pd.to_numeric(df[c], errors="coerce").fillna(0).astype("float32")
            num_cols.append(c)
        else:
            # Treat as categorical
            df[c] = df[c].astype("category")
            cat_cols.append(c)

    print(f"‚úÖ Categorical features: {cat_cols}")
    print(f"‚úÖ Numerical features: {num_cols}")

    return df, cat_cols


def stratified_downsample(df, per_class_max=PER_CLASS_MAX):
    groups = []
    for label, grp in df.groupby("Label"):
        if len(grp) > per_class_max:
            grp = resample(grp, replace=False, n_samples=per_class_max, random_state=RANDOM_STATE)
        groups.append(grp)
    out = pd.concat(groups, axis=0).drop_duplicates().sample(frac=1.0, random_state=RANDOM_STATE).reset_index(drop=True)
    print(f"‚úÖ After downsample: {out.shape}, class counts:\n{out['Label'].value_counts()}")
    return out

def train_in_chunks(params, train_pool, eval_pool, total_iters, chunk_iters, train_dir):
    os.makedirs(train_dir, exist_ok=True)
    done, model = 0, None
    t0 = time.time()
    while done < total_iters:
        add = min(chunk_iters, total_iters - done)
        this_params = {**params, "iterations": add, "train_dir": train_dir}
        m = CatBoostClassifier(**this_params)
        t_chunk0 = time.time()
        m.fit(train_pool, eval_set=eval_pool, init_model=model, verbose=100)
        t_chunk = time.time() - t_chunk0
        done += add
        elapsed = time.time() - t0
        it_per_sec = done / elapsed if elapsed > 0 else float("inf")
        remain = (total_iters - done) / it_per_sec if it_per_sec > 0 else float("inf")
        print(f"‚è±Ô∏è  Progress: {done}/{total_iters} | {add} iters in {t_chunk:.1f}s | ETA {remain:.1f}s")
        model = m
    return model

# def compute_shap(model, X_sample, cat_indices, run_dir):
#     """Compute SHAP values using CatBoost's built-in method and save plots."""
#     pool = Pool(X_sample, cat_features=cat_indices)
#     shap_values = model.get_feature_importance(data=pool, type="ShapValues")

#     # Drop base value, keep feature contributions
#     shap_values = shap_values[:, 1:]

#     # Ensure 1D vector
#     mean_abs_shap = np.abs(shap_values).mean(axis=0).ravel()

#     shap_df = pd.DataFrame({
#         "feature": list(X_sample.columns),
#         "mean_abs_shap": mean_abs_shap
#     }).sort_values("mean_abs_shap", ascending=False)

#     shap_df.to_csv(os.path.join(run_dir, "shap_values.csv"), index=False)

#     plt.figure(figsize=(10, 6))
#     shap_df.head(20).plot(kind="bar", x="feature", y="mean_abs_shap", legend=False)
#     plt.title("Top-20 Features by Mean SHAP Importance")
#     plt.tight_layout()
#     plt.savefig(os.path.join(run_dir, "shap_summary.png"))
#     plt.close()


def compute_shap(model, X_sample, cat_indices, run_dir):
    """Compute SHAP values using CatBoost's built-in method and save plots."""
    pool = Pool(X_sample, cat_features=cat_indices)
    shap_values = model.get_feature_importance(data=pool, type="ShapValues")

    # Drop bias column (first column is expected value)
    shap_values = shap_values[:, 1:]

    # Now average across samples
    mean_abs_shap = np.abs(shap_values).mean(axis=0).ravel()

    # ‚úÖ Make sure lengths match
    n_features = X_sample.shape[1]
    mean_abs_shap = mean_abs_shap[:n_features]

    shap_df = pd.DataFrame({
        "feature": list(X_sample.columns),
        "mean_abs_shap": mean_abs_shap
    }).sort_values("mean_abs_shap", ascending=False)

    shap_df.to_csv(os.path.join(run_dir, "shap_values.csv"), index=False)

    plt.figure(figsize=(10, 6))
    shap_df.head(20).plot(kind="bar", x="feature", y="mean_abs_shap", legend=False)
    plt.title("Top-20 Features by Mean SHAP Importance")
    plt.tight_layout()
    plt.savefig(os.path.join(run_dir, "shap_summary.png"))
    plt.close()




from sklearn.model_selection import train_test_split

def main():
    warnings.filterwarnings("ignore")
    run_dir = start_run_dir()
    print(f"üìÇ Run folder: {run_dir}\n")

    df = load_dataset(DATA_PATH)
    df, cat_cols = infer_and_fix_types(df)

    # ‚úÖ Use full dataset (no downsampling)
    print(f"‚úÖ Using full dataset: {df.shape}")

    # Drop identifying/leaky columns
    drop_cols = ["IPV4_SRC_ADDR", "IPV4_DST_ADDR", "ALERT"]
    X = df.drop(columns=["Label"] + [c for c in drop_cols if c in df.columns])
    y = df["Label"].values
    cat_indices = [X.columns.get_loc(c) for c in cat_cols if c in X.columns]

    # ‚úÖ Simple train-test split (e.g., 80/20)
    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,
                                                        test_size=0.2,
                                                        random_state=RANDOM_STATE)

    train_pool = Pool(X_train, y_train, cat_features=cat_indices)
    eval_pool = Pool(X_test, y_test, cat_features=cat_indices)

    train_dir = os.path.join(run_dir, "train_logs")
    try:
        print("üöÄ Training on GPU‚Ä¶")
        model = train_in_chunks(CB_PARAMS_GPU, train_pool, eval_pool,
                                CB_PARAMS_GPU["iterations"], CHUNK_ITERS, train_dir)
    except CatBoostError:
        print("üîÅ Falling back to CPU‚Ä¶")
        model = train_in_chunks(CB_PARAMS_CPU, train_pool, eval_pool,
                                CB_PARAMS_CPU["iterations"], CHUNK_ITERS, train_dir)

    # ‚úÖ Predict and report
    y_pred = model.predict(X_test).astype(int)
    report = classification_report(y_test, y_pred, output_dict=True)

    # Save confusion matrix
    cm = confusion_matrix(y_test, y_pred)
    plt.imshow(cm, interpolation='nearest')
    plt.title("Confusion Matrix")
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.colorbar()
    plt.tight_layout()
    cm_path = os.path.join(run_dir, "confusion_matrix.png")
    plt.savefig(cm_path, dpi=150)
    plt.close()
    print(f"üìå Confusion matrix saved ‚Üí {cm_path}")

    # SHAP (on sample of test set)
    shap_n = min(2000, len(X_test))
    X_sample = X_test.sample(n=shap_n, random_state=RANDOM_STATE)
    compute_shap(model, X_sample, cat_indices, run_dir)

    # Save metrics
    metrics_path = os.path.join(run_dir, "metrics.json")
    with open(metrics_path, "w") as f:
        json.dump(report, f, indent=2)
    print(f"\nüìå Classification report saved ‚Üí {metrics_path}")
    print("\n‚úÖ Done.")

if __name__ == "__main__":
    main()
